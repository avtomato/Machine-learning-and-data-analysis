## Задание по программированию: 1NN против RandomForest ##

В этом задании будет использоваться датасет *digits* из *sklearn.datasets*. Оставьте последние 25% объектов для контроля качества, разделив *X* и *y* на *X_train*, *y_train* и *X_test*, *y_test*.

Целью задания будет реализовать самый простой метрический классификатор — метод ближайшего соседа, а также сравнить качество работы реализованного вами *1NN* с *RandomForestClassifier* из *sklearn* на 1000 деревьях.

**Задание 1**

Реализуйте самостоятельно метод одного ближайшего соседа с евклидовой метрикой для задачи классификации. Можно не извлекать корень из суммы квадратов отклонений, т.к. корень — монотонное преобразование и не влияет на результат работы алгоритма.

Никакой дополнительной работы с признаками в этом задании делать не нужно — мы еще успеем этим заняться в других курсах. Ваша реализация может быть устроена следующим образом: можно для каждого классифицируемого объекта составлять список пар (расстояние до точки из обучающей выборки, метка класса в этой точке), затем сортировать этот список (по умолчанию сортировка будет сначала по первому элементу пары, затем по второму), а затем брать первый элемент (с наименьшим расстоянием).

Сортировка массива длиной *N* требует порядка *N log N* сравнений (строже говоря, она работает за *O(N log N)*). Подумайте, как можно легко улучшить получившееся время работы. Кроме простого способа найти ближайший объект всего за *N* сравнений, можно попробовать придумать, как разбить пространство признаков на части и сделать структуру данных, которая позволит быстро искать соседей каждой точки. За выбор метода поиска ближайших соседей в *KNeighborsClassifier* из *sklearn* отвечает параметр *algorithm* — если у вас уже есть некоторый бэкграунд в алгоритмах и структурах данных, вам может быть интересно познакомиться со структурами данных *ball tree* и *kd tree*.

Доля ошибок, допускаемых 1NN на тестовой выборке, — ответ в задании 1.

**Задание 2**

Теперь обучите на обучающей выборке *RandomForestClassifier(n_estimators=1000)* из *sklearn*. Сделайте прогнозы на тестовой выборке и оцените долю ошибок классификации на ней. Эта доля — ответ в задании 2. Обратите внимание на то, как соотносится качество работы случайного леса с качеством работы, пожалуй, одного из самых простых методов — *1NN*. Такое различие — особенность данного датасета, но нужно всегда помнить, что такая ситуация тоже может иметь место, и не забывать про простые методы.